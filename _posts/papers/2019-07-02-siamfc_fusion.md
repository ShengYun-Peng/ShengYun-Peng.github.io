---
layout: paper
categories: papers
permalink: papers/Fusion
id: Fusion
title: "Object Fusion Tracking Based on Visible and Infrared Images Using Fully Convolutional Siamese Networks"
authors:
  - Xingchen Zhang
  - Ping Ye
  - Dan Qiao
  - Junhao Zhao
  - ShengYun Peng
  - Gang Xiao
venue: 22th International Conference on Information Fusion (FUSION)
year: 2019
url: /papers/Fusion
pdf: /papers/19_Fusion.pdf
figure: /images/papers/19_Fusion.png
feature-title: "Object Fusion Tracking Based on Visible and Infrared Images Using Fully Convolutional Siamese Networks"
feature-description: Xingchen Zhang, Ping Ye, Dan Qiao, Junhao Zhao, â‰ˆ, Gang Xiao
image: /images/featured/19_siamfc-fusion.png
featured: false
feature-order: 201907
selected: false
type: conference
doi: ""
bibtex: |-

  @INPROCEEDINGS{9011253,
    title={Object Fusion Tracking Based on Visible and Infrared Images Using Fully Convolutional Siamese Networks},
    author={Zhang, Xingchen and Ye, Ping and Qiao, Dan and Zhao, Junhao and Peng, Shengyun and Xiao, Gang},
    booktitle={2019 22th International Conference on Information Fusion (FUSION)},
    year={2019},
    pages={1-8},
  }
---

Visual tracking is of great importance and thus has attracted a lot of interests in 
recent years. However, tracking based on visible images may fail when visible images 
are not reliable, for example when the illumination conditions are poor or in foggy 
day. Infrared images reveal thermal information thus are insensitive to these factors. 
Due to their complementary features, object fusion tracking based on visible and 
infrared images has attracted great attention recently. In this paper, a pixel-level 
fusion tracking method based on fully convolutional Siamese Networks, which has shown 
great potential in RGB object tracking, is proposed. Visible and infrared images are 
firstly fused and then tracking is performed based on fused images. Extensive experiments 
on a large dataset which contains challenging scenarios have been conducted to evaluate 
tracking performances. The results clearly indicate that the proposed fusion tracking 
method can improve tracking performance compared to methods based on images of single 
modality.