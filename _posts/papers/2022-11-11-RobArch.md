---
layout: paper
categories: papers
permalink: papers/robarch
id: robarch
title: "RobArch: Designing Robust Architectures against Adversarial Attacks"
authors:
  - ShengYun Peng
  - Weilin Xu
  - Cory Cornelius
  - Kevin Li
  - Rahul Duggal
  - Duen Horng Chau
  - Jason Martin
venue: arXiv
year: 2023
url: /papers/robarch
pdf: /papers/22_robarch.pdf
type: paper
figure: 
feature-title: RobArch&#58; Designing Robust Architectures against Adversarial Attacks
feature-description: 
image: /images/featured/22_robarch.png
featured: false
feature-order: 202211
selected: false
type: misc
doi: 
bibtex: |-

    @article{peng2023robarch,
      title={RobArch: Designing Robust Architectures against Adversarial Attacks},
      author={Peng, ShengYun and Xu, Weilin and Cornelius, Cory and Li, Kevin and Duggal, Rahul and Chau, Duen Horng and Martin, Jason},
      journal={arXiv preprint arXiv:2301.03110},
      year={2023}
    }
---

Adversarial Training is the most effective approach for improving the robustness of Deep Neural Networks (DNNs). However, compared to the large body of research in optimizing the adversarial training process, there are few investigations into how architecture components affect robustness, and they rarely constrain model capacity. Thus, it is unclear where robustness precisely comes from. In this work, we present the first large-scale systematic study on the robustness of DNN architecture components under fixed parameter budgets. Through our investigation, we distill 18 actionable robust network design guidelines that empower model developers to gain deep insights. We demonstrate these guidelinesâ€™ effectiveness by introducing the novel Robust Architecture (RobArch) model that instantiates the guidelines to build a family of top-performing models across parameter capacities against strong adversarial attacks. RobArch achieves the new state-of-the-art AutoAttack accuracy on the RobustBench ImageNet leaderboard.