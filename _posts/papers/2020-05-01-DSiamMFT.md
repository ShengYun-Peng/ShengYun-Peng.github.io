---
layout: paper
categories: papers
permalink: papers/DSiamMFT
id: DSiamMFT
title: "DSiamMFT: An RGB-T fusion tracking method via dynamic Siamese networks using multi-layer feature fusion"
authors:
  - Xingchen Zhang
  - Ping Ye
  - ShengYun Peng
  - Jun Liu
  - Gang Xiao
venue: Signal Processing, Image Communication
year: 2020
url: /papers/DSiamMFT
pdf: /papers/20_DSiamMFT.pdf
type: paper
figure: /images/papers/20_DSiamMFT.png
feature-title: 
feature-description: ""
image: 
featured: false
feature-order: 
selected: false
type: journal
doi: "10.1016/j.image.2019.115756"
bibtex: |-

  @article{ZHANG2020115756,
    title = {DSiamMFT: An RGB-T fusion tracking method via dynamic Siamese networks using multi-layer feature fusion},
    author = {Xingchen Zhang and Ping Ye and Shengyun Peng and Jun Liu and Gang Xiao},
    journal = {Signal Processing: Image Communication},
    year = {2020},
    volume = {84},
    pages = {115756},
    issn = {0923-5965},
    doi = {https://doi.org/10.1016/j.image.2019.115756},
    url = {https://www.sciencedirect.com/science/article/pii/S092359651930342X},
  }
---

The task of object tracking is very important since its various applications. 
However, most object tracking methods are based on visible images, which may fail 
when visible images are unreliable, for example when the illumination conditions 
are poor. To address this issue, in this paper a fusion tracking method which 
combines information from RGB and thermal infrared images (RGB-T) is presented based 
on the fact that infrared images reveal thermal radiation of objects thus providing 
complementary features. Particularly, a fusion tracking method based on dynamic 
Siamese networks with multi-layer fusion, termed as DSiamMFT, is proposed. 
Visible and infrared images are firstly processed by two dynamic Siamese Networks, 
namely visible and infrared network, respectively. Then, multi-layer feature fusion 
is performed to adaptively integrate multi-level deep features between visible and 
infrared networks. Response maps produced from different fused layer features are 
then combined through an elementwise fusion approach to produce the final response 
map, based on which the target can be located. Extensive experiments on large datasets 
with various challenging scenarios have been conducted. The results demonstrate that 
the proposed method shows very competitive performance against the-state-of-art RGB-T 
trackers. The proposed approach also improves tracking performance significantly 
compared to methods based on images of single modality.